{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2： 情感分析项目 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目的目标是基于用户提供的评论，通过算法自动去判断其评论是正面的还是负面的情感。比如给定一个用户的评论：\n",
    "- 评论1： “我特别喜欢这个电器，我已经用了3个月，一点问题都没有！”\n",
    "- 评论2： “我从这家淘宝店卖的东西不到一周就开始坏掉了，强烈建议不要买，真实浪费钱”\n",
    "\n",
    "对于这两个评论，第一个明显是正面的，第二个是负面的。 我们希望搭建一个AI算法能够自动帮我们识别出评论是正面还是负面。\n",
    "\n",
    "情感分析的应用场景非常丰富，也是NLP技术在不同场景中落地的典范。比如对于一个证券领域，作为股民，其实比较关注舆论的变化，这个时候如果能有一个AI算法自动给网络上的舆论做正负面判断，然后把所有相关的结论再整合，这样我们可以根据这些大众的舆论，辅助做买卖的决策。 另外，在电商领域评论无处不在，而且评论已经成为影响用户购买决策的非常重要的因素，所以如果AI系统能够自动分析其情感，则后续可以做很多有意思的应用。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "情感分析是文本处理领域经典的问题。整个系统一般会包括几个模块：\n",
    "- 数据的抓取： 通过爬虫的技术去网络抓取相关文本数据\n",
    "- 数据的清洗/预处理：在本文中一般需要去掉无用的信息，比如各种标签（HTML标签），标点符号，停用词等等\n",
    "- 把文本信息转换成向量： 这也成为特征工程，文本本身是不能作为模型的输入，只有数字（比如向量）才能成为模型的输入。所以进入模型之前，任何的信号都需要转换成模型可识别的数字信号（数字，向量，矩阵，张量...)\n",
    "- 选择合适的模型以及合适的评估方法。 对于情感分析来说，这是二分类问题（或者三分类：正面，负面，中性），所以需要采用分类算法比如逻辑回归，朴素贝叶斯，神经网络，SVM等等。另外，我们需要选择合适的评估方法，比如对于一个应用，我们是关注准确率呢，还是关注召回率呢？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次项目中，我们已经给定了训练数据和测试数据，它们分别是 train.positive.txt, train.negative.txt， test_combined.txt. 请注意训练数据和测试数据的格式不一样，详情请见文件内容。 整个项目你需要完成以下步骤：\n",
    "\n",
    "数据的读取以及清洗： 从给定的.txt中读取内容，并做一些数据清洗，这里需要做几个工作： （1） 文本的读取，需要把字符串内容读进来。 （2）去掉无用的字符比如标点符号，多余的空格，换行符等 （3） 分词\n",
    "把文本转换成TF-IDF向量： 这部分直接可以利用sklearn提供的TfidfVectorizer类来做。\n",
    "利用逻辑回归模型来做分类，并通过交叉验证选择最合适的超参数\n",
    "利用支持向量机做分类，并通过交叉验证选择神经网络的合适的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Reading: 文本读取 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.csdn.net/u011371629/article/details/91348043\n",
    "# https://blog.csdn.net/lt326030434/article/details/83383614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_file(file_path):\n",
    "    comments = []  # 用来存储评论\n",
    "    labels = []   # 存储标签\n",
    "    with open(file_path,encoding='utf-8') as file:\n",
    "        # TODO 提取每一个评论，然后利用process_line函数来做处理，并添加到comments。\n",
    "        text = file.read().replace(' ','').replace('\\n','')\n",
    "        reg = '<reviewid=\"\\d{1,4}\">(.*?)</review>'\n",
    "        result = re.findall(reg,text)\n",
    "        for r in result:\n",
    "            comments.append(r)\n",
    "            if file_path == 'data/train.positive.txt':\n",
    "                labels.append('1')\n",
    "            else:\n",
    "                labels.append('0')\n",
    "    return comments, labels\n",
    "\n",
    "def read_test_file(file_path):\n",
    "    comments = []  # 用来存储评论\n",
    "    labels = []   # 存储标签\n",
    "    with open(file_path,encoding='utf-8') as file:\n",
    "        # TODO 提取每一个评论，然后利用process_line函数来做处理，并添加到comments。\n",
    "        text = file.read().replace(' ','').replace('\\n','')\n",
    "        reg = '<reviewid=\"\\d{1,4}\".*?</review>'\n",
    "        result = re.findall(reg,text)\n",
    "        for r in result:\n",
    "            label_reg = '<reviewid=\"\\d{1,4}\"label=\"(\\d)\">'\n",
    "            com_reg = '>(.*?)</review>'\n",
    "            label = re.findall(label_reg,r)[0]\n",
    "            comment = re.findall(com_reg,r)[0]\n",
    "            labels.append(label)\n",
    "            comments.append(comment)\n",
    "    return comments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file():\n",
    "    \"\"\"\n",
    "    读取训练数据和测试数据，并对它们做一些预处理\n",
    "    解析标签中的内容\n",
    "    \"\"\"    \n",
    "    train_pos_file = \"data/train.positive.txt\"\n",
    "    train_neg_file = \"data/train.negative.txt\"\n",
    "    test_comb_file = \"data/test.combined.txt\"\n",
    "    \n",
    "    # TODO: 读取文件部分，把具体的内容写入到变量里面\n",
    "    train__pos_comments,train_pos_labels = read_train_file(train_pos_file)\n",
    "    \n",
    "    train__neg_comments,train_neg_labels = read_train_file(train_neg_file)\n",
    "    \n",
    "    test_comments,test_labels = read_test_file(test_comb_file)\n",
    "    return train__pos_comments,train_pos_labels,train_labels,train__neg_comments,train_neg_labels ,test_comments,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorary Analysis: 做一些简单的可视化分析 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8065, 8065, 2500, 2500)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练数据和测试数据大小\n",
    "train__pos_comments,train_pos_labels,train_labels,train__neg_comments,train_neg_labels ,test_comments,test_labels=process_file()\n",
    "train_comments=train__pos_comments+train__neg_comments\n",
    "train_labels=train_pos_labels+train_neg_labels\n",
    "(len(train_comments), len(train_labels), len(test_comments), len(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请问这机不是有个遥控器的吗？\n"
     ]
    }
   ],
   "source": [
    "print(train__pos_comments[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\seaborn\\distributions.py:218: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  color=hist_color, **hist_kws)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\seaborn\\distributions.py:218: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  color=hist_color, **hist_kws)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c5b856bc18>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: 对于训练数据中的正负样本，分别画出一个histogram， histogram的x抽是每一个样本中字符串的长度，y轴是拥有\n",
    "# 这个长度的样本的百分比。\n",
    "#       并说出样本长度是否对情感有相关性 (需要先用到结巴分词)\n",
    "#       参考：https://en.wikipedia.org/wiki/Histogram\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def count_sentence(sentences):\n",
    "    len_list = []\n",
    "    for s in sentences:\n",
    "        sentence = []\n",
    "        for i in jieba.cut(s):\n",
    "            sentence.append(i)\n",
    "        len_list.append(len(sentence))\n",
    "    return len_list\n",
    "sns.distplot(count_sentence(train__pos_comments))   # train_pos_comments样本中各长度样本所占百分比\n",
    "sns.distplot(count_sentence(train__neg_comments))   # train_neg_comments样本中各长度样本所占百分比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正负样本长度所占比例基本相近,说明样本长度与情感没有相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['，', '的', '。', '了', '是', '！', '很', ',', '我', '也', '在', '有', '~', '都', '好', '.', '不错', '就', '买', '喜欢']\n",
      "['，', '的', '。', '了', '！', '是', '我', ',', '不', '买', '就', '也', '都', '很', '有', '在', '？', '没有', '!', '.']\n",
      "stop_words:['的', '了', '是', '很', '我', '也', '在', '有', '都', '就', '买']\n"
     ]
    }
   ],
   "source": [
    "# TODO： 分别列出训练数据中正负样本里的top 20单词（可以做适当的stop words removal）。 \n",
    "import collections\n",
    "\n",
    "\n",
    "def get_top20_words(comments):\n",
    "    word_library = []   # 储存所有词\n",
    "    for comment in comments:\n",
    "        for i in jieba.cut(comment):\n",
    "            word_library.append(i)\n",
    "    word_dic = collections.Counter(word_library).most_common(20)\n",
    "    top20_list = [i[0] for i in word_dic]\n",
    "    return top20_list\n",
    "print(get_top20_words(train__pos_comments))\n",
    "print(get_top20_words(train__neg_comments))\n",
    "\n",
    "pos_20=get_top20_words(train__pos_comments)\n",
    "neg_20=get_top20_words(train__neg_comments)\n",
    "# 将正面评价和负面评价中共同出现的词作为停用词\n",
    "stop_words = []\n",
    "for word in get_top20_words(pos_20):\n",
    "    if word in get_top20_words(neg_20) and word.isalnum():\n",
    "        stop_words.append(word)\n",
    "print('stop_words:' + str(stop_words))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Cleaning: 文本处理部分 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "终于 找到 同道中人 啦 从 初中 开始 已经 喜欢 上 michaeljackson 但 同学 们 用 鄙夷 眼光 看 他们 人为 jackson 样子 古怪 甚至 说 丑 当场 气晕 但 现在 同道中人 好开心 michaeljacksonisthemostsuccessfulsingerintheworld \n"
     ]
    }
   ],
   "source": [
    "# TODO：对于train_comments, test_comments进行字符串的处理，几个考虑的点：\n",
    "#   1. 停用词过滤\n",
    "#   2. 去掉特殊符号\n",
    "#   3. 去掉数字（比如价格..)\n",
    "#   4. ...\n",
    "#   需要注意的点是，由于评论数据本身很短，如果去掉的太多，很可能字符串长度变成0\n",
    "#   预处理部分，可以自行选择合适的方.\n",
    "train_comments_new = [] \n",
    "test_comments_new = []\n",
    "import string\n",
    "\n",
    "def text_preprocessing(comments):\n",
    "    comments_new = []\n",
    "    for comment in comments:\n",
    "        sentence = ''\n",
    "        for word in list(jieba.cut(comment)):\n",
    "            # 去除停用词、标点符号、数字\n",
    "            if word not in set(stop_words) and word.isalnum() and not word.isdigit():\n",
    "                sentence += word + ' '\n",
    "        comments_new.append(sentence)\n",
    "    return comments_new\n",
    "    \n",
    "train_comments_new = text_preprocessing(train_comments)\n",
    "test_comments_new = text_preprocessing(test_comments)\n",
    "\n",
    "\n",
    "print(test_comments_new[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction : 从文本中提取特征 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8065, 43903) (2500, 43903) (8065,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "# TODO: 利用tf-idf从文本中提取特征,写到数组里面. \n",
    "#       参考：https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf=TfidfVectorizer()\n",
    "X_train = tf.fit_transform(train_comments)\n",
    "y_train = np.array(train_labels)\n",
    "X_test =   tf.transform(test_comments)\n",
    "y_test =   np.array(test_labels)\n",
    "\n",
    "print (np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling: 训练模型以及选择合适的超参数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.17      0.28      1250\n",
      "           1       0.53      0.94      0.68      1250\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      2500\n",
      "   macro avg       0.64      0.56      0.48      2500\n",
      "weighted avg       0.64      0.56      0.48      2500\n",
      "\n",
      "训练数据上的准确率为：0.999008059516429\n",
      "测试数据上的准确率为: 0.5564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# TODO： 利用逻辑回归来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       逻辑回归的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#       对于逻辑回归，经常调整的超参数为： C\n",
    "\n",
    "parameters = { 'C':np.logspace(-3,3,7)}\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "# 打印在训练数据上的准确率\n",
    "print(\"训练数据上的准确率为：\" + str(clf.score(X_train, y_train)))\n",
    "# # 打印在测试数据上的准确率\n",
    "print(\"测试数据上的准确率为: \" + str(clf.score(X_test, y_test)))\n",
    "test_comment1 = '这个宝贝还是比较不错滴'\n",
    "test_comment2 = '很不好，太差了'\n",
    "\n",
    "def process_text(text=''):\n",
    "\n",
    "    text = ''.join(e for e in text if e.isalnum() and not e.isdigit() and e not in set(stop_words))\n",
    "    return ', '.join(jieba.cut(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 出现过拟合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['不好, 太, 差']\n",
      "  (0, 3841)\t1.0\n",
      "['0']\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "test.append(process_text(test_comment2))\n",
    "print(test)\n",
    "print(tf.transform(test))\n",
    "print(clf.predict(tf.transform(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/26/9842333adbb8f17bcb3d699400a8b1ccde0af0b6de8d07224e183728acdf/bayesian_optimization-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.0 in d:\\soft\\anaconda\\lib\\site-packages (from bayesian-optimization) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in d:\\soft\\anaconda\\lib\\site-packages (from bayesian-optimization) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in d:\\soft\\anaconda\\lib\\site-packages (from bayesian-optimization) (0.20.3)\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.0, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.17      0.28      1250\n",
      "           1       0.53      0.95      0.68      1250\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      2500\n",
      "   macro avg       0.65      0.56      0.48      2500\n",
      "weighted avg       0.65      0.56      0.48      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# TODO： 利用SVM来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       SVM的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#       对于SVM模型，经常调整的超参数为：C, gamma, kernel\n",
    "# import sklearn.model_selection as model_selection\n",
    "# from sklearn.cross_validation import cross_val_score\n",
    "parameters = {'kernel':('linear', 'rbf', 'poly', 'sigmoid'), 'C':np.logspace(-3,3,7)}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于超参数的调整，我们经常使用gridsearch，这也是工业界最常用的方法，但它的缺点是需要大量的计算，所以近年来这方面的研究也成为了重点。 其中一个比较经典的成果为Bayesian Optimization（利用贝叶斯的思路去寻找最好的超参数）。Ryan P. Adams主导的Bayesian Optimization利用高斯过程作为后验概率（posteior distribution）来寻找最优解。 https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf 在下面的练习中，我们尝试使用Bayesian Optimization工具来去寻找最优的超参数。参考工具：https://github.com/fmfn/BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |   gamma   |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.4381  \u001b[0m | \u001b[0m 4.475   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.9728  \u001b[0m | \u001b[0m 7.114   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.7211  \u001b[0m | \u001b[0m 12.65   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.5643  \u001b[0m | \u001b[0m 19.11   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.907   \u001b[0m | \u001b[0m 14.32   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.737   \u001b[0m | \u001b[0m 2.013   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.1078  \u001b[0m | \u001b[0m 19.99   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.7285  \u001b[0m | \u001b[0m 2.001   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.5083  \u001b[0m | \u001b[0m 19.99   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.4991  \u001b[0m | \u001b[0m 2.037   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.7561  \u001b[0m | \u001b[0m 19.93   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.08873 \u001b[0m | \u001b[0m 2.061   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.02516 \u001b[0m | \u001b[0m 19.98   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.5539  \u001b[0m | \u001b[0m 2.14    \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.04943 \u001b[0m | \u001b[0m 19.9    \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.3102  \u001b[0m | \u001b[0m 2.007   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.7176  \u001b[0m | \u001b[0m 19.99   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2068  \u001b[0m | \u001b[0m 2.05    \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 19.94   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.3128  \u001b[0m | \u001b[0m 2.052   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.01575 \u001b[0m | \u001b[0m 19.88   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2355  \u001b[0m | \u001b[0m 2.058   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.9946  \u001b[0m | \u001b[0m 19.96   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2967  \u001b[0m | \u001b[0m 2.03    \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.3071  \u001b[0m | \u001b[0m 19.99   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2713  \u001b[0m | \u001b[0m 19.99   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.09117 \u001b[0m | \u001b[0m 2.032   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2139  \u001b[0m | \u001b[0m 2.041   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.9836  \u001b[0m | \u001b[0m 19.89   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.6196  \u001b[0m | \u001b[0m 0.2814  \u001b[0m | \u001b[0m 2.057   \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# TODO: 仍然使用SVM模型，但在这里使用Bayesian Optimization来寻找最好的超参数。 \n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用Bayesian Optimization https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       SVM的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#       对于SVM模型，经常调整的超参数为：C, gamma, kernel\n",
    "#       参考Bayesian Optimization开源工具： https://github.com/fmfn/BayesianOptimization\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm_cv(C, gamma):\n",
    "    svm = SVC(C=10 ** C, gamma=10 ** gamma,random_state=1)\n",
    "    val = cross_val_score(svm,X_train, y_train, cv=5).mean()\n",
    "    return val\n",
    "\n",
    "pbounds = {'C':(0,1),'gamma':(2,20)}\n",
    "svm_bo = BayesianOptimization(svm_cv,pbounds=pbounds)\n",
    "\n",
    "svm_bo.maximize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 特征: 添加n-gram特征 (10分)\n",
    "在原有tf-idf特征的基础上，添加n-gram特征（在这里我们使用bi-gram特征）。添加完之后效果是否有提升？ 为什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8065, 43903) (2500, 43903) (8065,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(train_comments)  # 添加完bigram之后的特征\n",
    "y_train = np.array(train_labels)                    # \n",
    "X_test = vectorizer.transform(test_comments)        # 添加完bigram之后的特征\n",
    "y_test = np.array(test_labels)                      # \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-06 5.99484250e-05 3.59381366e-03 2.15443469e-01\n",
      " 1.29154967e+01 7.74263683e+02 4.64158883e+04 2.78255940e+06\n",
      " 1.66810054e+08 1.00000000e+10]\n"
     ]
    }
   ],
   "source": [
    "print(np.logspace(-6,10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 774.2636826811278}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.17      0.27      1250\n",
      "           1       0.53      0.95      0.68      1250\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      2500\n",
      "   macro avg       0.65      0.56      0.48      2500\n",
      "weighted avg       0.65      0.56      0.48      2500\n",
      "\n",
      "训练数据上的准确率为：0.9991320520768754\n",
      "测试数据上的准确率为: 0.5584\n"
     ]
    }
   ],
   "source": [
    "## TODO 模型的训练，如上\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# TODO： 利用逻辑回归来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       逻辑回归的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#       对于逻辑回归，经常调整的超参数为： C\n",
    "\n",
    "parameters = { 'C':np.logspace(-6,10,10)}\n",
    "# parameters={'C':[0.1,0.01,0.21,0.001]}\n",
    "lr = LogisticRegression()\n",
    "clf = GridSearchCV(lr, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "# 打印在训练数据上的准确率\n",
    "print(\"训练数据上的准确率为：\" + str(clf.score(X_train, y_train)))\n",
    "# # 打印在测试数据上的准确率\n",
    "print(\"测试数据上的准确率为: \" + str(clf.score(X_test, y_test)))\n",
    "test_comment1 = '这个宝贝还是比较不错滴'\n",
    "test_comment2 = '很不好，太差了'\n",
    "\n",
    "def process_text(text=''):\n",
    "\n",
    "    text = ''.join(e for e in text if e.isalnum() and not e.isdigit() and e not in set(stop_words))\n",
    "    return ', '.join(jieba.cut(text))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "param_hidden_layer_sizes = np.linspace(10, 200, 20)  # 针对参数 “hidden_layer_sizes”, 尝试几个不同的值\n",
    "param_alphas = np.logspace(-4,1,6)  # 对于参数 \"alpha\", 尝试几个不同的值\n",
    "\n",
    "best_hidden_layer_size = param_hidden_layer_sizes[0]\n",
    "best_alpha = param_alphas[0]\n",
    "\n",
    "for size in param_hidden_layer_sizes:\n",
    "    for val in param_alphas:\n",
    "        # TODO 编写交叉验证的过程，需要做5-fold交叉验证。\n",
    "        avg = 0\n",
    "        for train_index, test_index in kf.split(X_train, y_train):\n",
    "            mlp = MLPClassifier(alpha=int(val),hidden_layer_sizes=int(size))\n",
    "            mlp.fit(X_train[train_index],y_train[train_index])\n",
    "            avg += mlp.score(X_train[test_index],y_train[test_index])\n",
    "        acc_avg = avg/5\n",
    "        if acc_avg > best_acc:\n",
    "            best_acc = acc_avg\n",
    "            best_hidden_layer_size = size\n",
    "            best_alpha = val\n",
    "\n",
    "print (\"最好的参数hidden_layer_size值为： %f\" % (best_hidden_layer_size))\n",
    "print (\"最好的参数alpha值为： %f\" % (best_alpha))\n",
    "\n",
    "# TODO 我们需要在整个训练数据上重新训练模型，但这次使用最好的参数hidden_layer_size和best_alpha\n",
    "mlp = MLPClassifier(alpha=best_alpha,hidden_layer_sizes=best_hidden_layer_size).fit(X_train,y_train)\n",
    "# 打印在训练数据上的准确率\n",
    "print (\"训练数据上的准确率为：\" + str(mlp.score(X_train, y_train)))\n",
    "\n",
    "# 打印在测试数据上的准确率\n",
    "print (\"测试数据上的准确率为: \" + str(mlp.score(X_test, y_test)))     \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
